import requests
from bs4 import BeautifulSoup
from dotenv import load_dotenv
import os

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

SLACK_WEBHOOK_URL = os.getenv("SLACK_WEBHOOK_URL")

def post_news_to_slack(news_list):
    """
    ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ãƒªã‚¹ãƒˆï¼ˆ(title, url)ï¼‰ã‚’Slackã«æŠ•ã’ã‚‹ã€‚
    """
    if not news_list:
        return
    if not SLACK_WEBHOOK_URL:
        print("SLACK_WEBHOOK_URL is not set in the .env file.")
        return
    for title, url in news_list:
        # ã‚¿ã‚¤ãƒˆãƒ«ã‚’å¤ªå­—ã€å†’é ­ã«çµµæ–‡å­—ã€ã‚¿ã‚¤ãƒˆãƒ«ã¨URLã®é–“ã‚’1è¡Œç©ºã‘ã‚‹
        text = f"ğŸ“¢ *{title}*\n\n{url}"
        payload = {
            "text": text
        }
        try:
            response = requests.post(SLACK_WEBHOOK_URL, json=payload, timeout=10)
            response.raise_for_status()
        except Exception as e:
            print(f"Error posting to Slack: {e}")

def fetch_itmedia_news_top(limit: int = 5):
    keywords = ["AI", "ã‚¯ãƒ©ã‚¦ãƒ‰", "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£"]  # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å®šç¾©

    url = "https://www.itmedia.co.jp/news/"
    headers = {
        "User-Agent": (
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/120.0.0.0 Safari/537.36"
        )
    }

    resp = requests.get(url, headers=headers, timeout=10)
    resp.encoding = resp.apparent_encoding
    resp.raise_for_status()  # ã‚¨ãƒ©ãƒ¼æ™‚ã«ä¾‹å¤–ã‚’æŠ•ã’ã‚‹

    soup = BeautifulSoup(resp.text, "html.parser")

    # ãƒˆãƒƒãƒ—ã‚¹ãƒˆãƒ¼ãƒªãƒ¼æ ï¼ˆcolBoxTopStoriesï¼‰ã‹ã‚‰è¨˜äº‹ä¸€è¦§ã‚’å–å¾—
    news_links = []
    base_url = "https://www.itmedia.co.jp"

    top_stories = soup.find("div", id="colBoxTopStories")
    if not top_stories:
        print("colBoxTopStories not found")
        return

    # .colBoxTitle å†…ã® a ã‚¿ã‚°ãŒè¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ï¼‹ãƒªãƒ³ã‚¯
    for a in top_stories.select(".colBoxTitle a"):
        title = (a.get_text() or "").strip()
        href = (a.get("href") or "").strip()
        if not title or not href:
            continue

        # href ãŒç›¸å¯¾ãƒ‘ã‚¹ãªã‚‰ã‚µã‚¤ãƒˆã® base ã‚’è£œã†
        if href.startswith("/"):
            href = base_url + href
        elif not href.startswith("http"):
            href = base_url + "/" + href.lstrip("/")

        # è¦‹å‡ºã—ã« keywords ã®ã„ãšã‚Œã‹ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿è¿½åŠ 
        if any(keyword in title for keyword in keywords):
            news_links.append((title, href))

    # é‡è¤‡ã‚’é™¤å¤–
    seen = set()
    unique_news = []
    for title, href in news_links:
        if href not in seen and len(title) > 0:
            seen.add(href)
            unique_news.append((title, href))

    # ä¸Šä½ limit ä»¶ã ã‘å–ã‚Šå‡ºã—
    news_to_notify = unique_news[:limit]

    # ä¸Šä½ limit ä»¶ã ã‘å‡ºåŠ›
    for i, (title, href) in enumerate(news_to_notify, start=1):
        print(f"{i}. {title}")
        print(f"   {href}")
        print()

    # ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒ1ä»¶ä»¥ä¸Šã‚ã£ãŸå ´åˆã®ã¿Slacké€šçŸ¥
    if news_to_notify:
        post_news_to_slack(news_to_notify)

if __name__ == "__main__":
    fetch_itmedia_news_top(limit=5)